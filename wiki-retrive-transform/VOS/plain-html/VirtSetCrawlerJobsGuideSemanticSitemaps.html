<html><body><div class="topic-text"><!--Begin of %META:TOPICPARENT{name="VirtSetCrawlerJobsGuide"}%--><p> </p>
<!--End of %META:TOPICPARENT{name="VirtSetCrawlerJobsGuide"}%--><p> </p>
<h1><a name="Setting up a Content Crawler Job to retrieve Semantic Sitemaps"></a>Setting up a Content Crawler Job to retrieve Semantic Sitemaps</h1>
<p> The following guide describes how to set up crawler job for getting Semantic Sitemap&#39;s content -- a variation of standard sitemap:</p>
<ol><li>Go to Conductor UI.
 For ex.
 at <a href="http://localhost:8890/conductor" class="absuri">http://localhost:8890/conductor</a> . </li>
<li>Enter dba credentials.
</li>
<li>Go to &quot;Web Application Server&quot;.
<br><br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr1.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr1.png" width="600px"></a><br><br> </li>
<li>Go to &quot;Content Imports&quot;.
<br><br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr2.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr2.png" width="600px"></a><br><br> </li>
<li>Click &quot;New Target&quot;.
<br><br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr3.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr3.png" width="600px"></a><br><br> </li>
<li>In the shown form: <ul><li>Enter for &quot;Crawl Job Name&quot;: <br><pre><br>Semantic Web Sitemap Example 
</pre><br></li>
<li>Enter for &quot;Data Source Address (URL)&quot;: <br><pre><br>http://www.connexfilter.com/sitemap_en.xml
</pre><br></li>
<li>Enter the location in the Virtuoso <a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/WebDAV" class="wikiword">WebDAV</a> repository the crawled should stored in the &quot;Local <a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/WebDAV" class="wikiword">WebDAV</a> Identifier &quot; text-box, for example, if user demo is available, then: <br><pre><br>/DAV/home/demo/semantic_sitemap/
</pre><br></li>
<li>Choose the &quot;Local resources owner&quot; for the collection from the list box available, for ex: user demo.
</li>
<li>Hatch &quot;Semantic Web Crawling&quot;: <ul><li>Note: when you select this option, you can either: <ol><li>Leave the Store Function and Extract Function empty - in this case the system Store and Extract functions will be used for the Semantic Web Crawling Process, or: </li>
<li>You can select your own Store and Extract Functions.
 <a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtSetCrawlerJobsGuideSemanticSitemapsFuncExample" class="wikiword">View an example of these functions</a>.
</li>
</ol></li>
</ul></li>
<li>Hatch &quot;Accept RDF&quot; <br><br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr16.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr16.png" width="600px"></a> <br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr17.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr17.png" width="600px"></a><br><br> </li>
<li>Optionally you can hatch &quot;Store metadata *&quot; and specify which RDF Cartridges to be included from the Sponger: <br><br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr17a.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr17a.png" width="600px"></a><br><br> </li>
</ul></li>
<li>Click the button &quot;Create&quot;.
<br><br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr18.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr18.png" width="600px"></a><br><br> </li>
<li>Click &quot;Import Queues&quot;.
<br><br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr19.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr19.png" width="600px"></a><br><br> </li>
<li>For &quot;Robot target&quot; with label &quot;Semantic Web Sitemap Example&quot; click &quot;Run&quot;.
</li>
<li>As result should be shown the number of the pages retrieved.
<br><br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr20.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr20.png" width="600px"></a><br><br> </li>
<li>Check the retrieved RDF data from your Virtuoso instance SPARQL endpoint <a href="http://cname:port/sparql" class="absuri">http://cname:port/sparql</a> with the following query selecting all the retrieved graphs for ex: <br><pre><br>SELECT ?g 
FROM &lt;http://localhost:8890/&gt;
WHERE 
  { 
    graph ?g { ?s ?p ?o } . 
    FILTER ( ?g LIKE &lt;http://www.connexfilter.com/%&gt; ) 
  }
</pre><br><br><br><a href="VirtSetCrawlerJobsGuideSemanticSitemaps/cr21.png" target="_blank"><img src="VirtSetCrawlerJobsGuideSemanticSitemaps/cr21.png" width="600px"></a><br><br></li>
</ol><p> </p>
<h2><a name="Related"></a>Related</h2>
<ul><li><a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtSetCrawlerJobsGuide" class="wikiword">Setting up Crawler Jobs Guide using Conductor</a> </li>
<li><a href="http://docs.openlinksw.com/virtuoso/rdfinsertmethods.html#rdfinsertmethodvirtuosocrawler" class="absuri">Setting up a Content Crawler Job to Add RDF Data to the Quad Store</a> </li>
<li><a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtSetCrawlerJobsGuideSitemaps" class="wikiword">Setting up a Content Crawler Job to Retrieve Sitemaps (where the source includes RDFa)</a> </li>
<li><a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtSetCrawlerJobsGuideDirectories" class="wikiword">Setting up a Content Crawler Job to Retrieve Content from Specific Directories</a> </li>
<li><a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtCrawlerSPARQLEndpoints" class="wikiword">Setting up a Content Crawler Job to Retrieve Content from SPARQL endpoint</a> </li>
</ul></div></body></html>