<html><body><div class="topic-text"><!--Begin of %META:TOPICPARENT{name="VOSIndex"}%--><p> </p>
<!--End of %META:TOPICPARENT{name="VOSIndex"}%--><p> </p>
<h1><a name="Quad Store Data Loading via Virtuoso's In-built Content Crawler"></a> Quad Store Data Loading via Virtuoso&#39;s In-built Content Crawler</h1>
<p>This guide covers the use of Virtuoso&#39;s in-built content crawler as a mechanism for scheduled of one-off data loading operations for its native quad store.</p>
<h2><a name="Why is this important?"></a> Why is this important?</h2>
<p>Transforming external data sources into Linked Data &quot;on the fly&quot; (e.g., via the &#39;Sponger&#39;) is sufficient for many use cases, but there are times when the volume or sheer nature of a data source makes batch-loading necessary.
 For example, Freebase offers RDF representations of its data, but it doesn&#39;t publish RDF dumps; even if it did, such dumps would usually be outdated by the time they were loaded.
 Thus, a scheduled crawl of that resource collection offers a viable alternative.</p>
<h2><a name="How to Set Up the Content Crawler for Linked Data generation and import"></a> How to Set Up the Content Crawler for Linked Data generation and import</h2>
<p>The Virtuoso Conductor can be used to set up various Content Crawler Jobs:</p>
<ul><li><a href="http://docs.openlinksw.com/virtuoso/rdfinsertmethods.html#rdfinsertmethodvirtuosocrawler" class="absuri">Setting up a Content Crawler Job to Import Linked Data into the Virtuoso Quad Store</a> </li>
<li><a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtSetCrawlerJobsGuideSitemaps" class="wikiword">Setting up a Content Crawler Job to Retrieve Sitemaps</a> (when the source includes RDFa) </li>
<li><a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtSetCrawlerJobsGuideSemanticSitemaps" class="wikiword">Setting up a Content Crawler Job to Retrieve Semantic Sitemaps</a> (a variation of the standard sitemap) </li>
<li><a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtSetCrawlerJobsGuideDirectories" class="wikiword">Setting up a Content Crawler Job to Retrieve Content from Specific Directories</a> </li>
<li><a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtCrawlerGuideAtom" class="wikiword">Setting up a Content Crawler Job to Retrieve Content from ATOM feed</a> </li>
<li><a href="http://vos.openlinksw.com:80/dataspace/owiki/wiki/VOS/VirtCrawlerSPARQLEndpoints" class="wikiword">Setting up a Content Crawler Job to Retrieve Content from SPARQL endpoint</a> </li>
</ul></div></body></html>