<?xml version="1.0" encoding="UTF-8"?>
<section xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://docbook.org/ns/docbook" xml:id="vdbparallelopandrtables">
      <title>Parallel Operations and Bulk Data Transfer with Remote Tables</title>
      <para>Especially when bulk copying data from a remote database into Virtuoso, parallel operation is essential
    	for performance.
    </para>
      <para>From version 7.00.3206, automatic query parallelization applies to selected remote table operations.
    </para>
      <para>If read committed isolation is sufficient for remote table access, the remote table access is
    	automatically parallelized if there is an integer key in the remote table that can be used for
    	partitioning.
    </para>
      <para>When the table is attached or when its statistics are updated with sys_stat_analyze, the remote
    	schema is read and if there is a numeric first part of primary key, its minimum and maximum values
    	are read. Samples of rows are read from the table at different ranges between the minimum and maximum
    	and the values are used for filling in column value statistics in sys_col_stat.
    </para>
      <para>If a remote table operation has no condition on the first part of primary key, a range condition is
    	automatically added if the scan of the remote table is the first in a sequence of nested joins. This is
    	the case for example when scanning the table inside a group by, order by, hash join build side or other
    	operation that does not immediately return rows to the client. The number of parallel ranges is given by
    	ThreadsPerQuery in the ini file, accessed as enable_qp with sys_stat and __dbf_set. In a cluster setting,
    	the same DSN is expected to be defined on all processes. The cluster splitting will scan a range per each
    	slice of the elastic cluster.
    </para>
      <para>The lowest range does not specify a low bound and the highest does not specify an upper bound, thus
    	the min and max of the range column do not have to be exactly up to date.
    </para>
      <para>It may be that the primary key of the remote table does not start with a numeric column. If this is
    	the case but there still exists a column usable for splitting a scan, one can create the table in Virtuoso
    	and declare the splitting column as first in the primary key. One can then use vd_remote_table to declare
    	the modified table as remote and use sys_stat_analyze for getting the statistics. After this, parallel
    	scans with the selected column used for setting ranges can be done.
    </para>
      <para>Use the explain function to verify that a scan is actually parallel. One expects to see the text of
    	the remote select followed by "split by range of &lt;column name&gt;" below the text of the remote
    	statement.
    </para>
      <para>In a parallel scan each range is scanned over a different connection. The transaction contexts are
    	independent and the isolation cannot be higher than read committed. Setting a higher isolation level or
    	selecting for update disables the parallel scan feature.
    </para>
      <para>The below snippet copies a table from another Virtuoso.</para>
      <programlisting>
use R1;
ATTACH TABLE lineitem
        FROM '1208'
        USER 'dba'
    PASSWORD 'dba';
</programlisting>
      <para>This makes a a remote table R1.1208.LINEITEM. This is the lineitem table from the DSN "1208".</para>
      <para>Now make a local table:</para>
      <programlisting>
use DB;
CREATE TABLE LINEITEM (
    L_ORDERKEY        INTEGER NOT NULL,
    L_PARTKEY         INTEGER NOT NULL,
    L_SUPPKEY         INTEGER NOT NULL,
    L_LINENUMBER      INTEGER NOT NULL,
    L_QUANTITY        double precision NOT NULL,
    L_EXTENDEDPRICE   double precision NOT NULL,
    L_DISCOUNT        double precision NOT NULL,
    L_TAX             double precision NOT NULL,
    L_RETURNFLAG      CHAR(1) NOT NULL,
    L_LINESTATUS      CHAR(1) NOT NULL,
    L_SHIPDATE        DATE NOT NULL,
    L_COMMITDATE      DATE NOT NULL,
    L_RECEIPTDATE     DATE NOT NULL,
    L_SHIPINSTRUCT    CHAR(25) NOT NULL,
    L_SHIPMODE        CHAR(10) NOT NULL,
    L_COMMENT         VARCHAR(44) NOT NULL,
    PRIMARY KEY       (L_ORDERKEY, L_LINENUMBER) column );
</programlisting>
      <para>Note the column modifier after the primary key. This ensures that the table is created in the column
    	store mode. When copying large tables over VDB, this is nearly always done for warehousing, not for OLTP,
    	so the column store mode is essentially always best. Insert is faster and the table takes much less
    	space.
    </para>
      <para>To transfer the data from the remote table into the local one:</para>
      <programlisting>
log_enable (2);
INSERT INTO lineietm
     SELECT *
       FROM r1..llineiten;
checkpoint;
</programlisting>
      <para>log_enabel (2) turns off logging an transactions and allows auto committing insert. The explicit
    	checkpoint makes the changes durable. Killing the database server during the transfer would start without
    	any of the effects of the transfer since there is no logging. The data reading and insertion is
    	automatically parallelized.
    </para>
      <para>Most such data transfer operations are in fact network bound since the local insert rate is well in
    	excess of 100MB/s on a commodity server and a 1gbE connection may only transfer around 80MB/s.
    </para>
      <para>The database is normally online during the transfer and the progress may be tracked by periodically
    	counting the target table.
    </para>
    </section>
