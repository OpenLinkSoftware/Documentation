


H1 Virtuoso Column Store 




As of version 7, Virtuoso offers a column-wise compressed storage
format alongside its traditional row-wise storage format. 

In the column-wise storage model, each column of a table or index is
stored contiguously, so that values of a single column on consecutive
rows are physically adjacent. In this way, adjacent values are of the
same type, and if the index is sorted on said value, the consecutive
values often form an ascending sequence. This organization allows
using more powerful compression techniques than could be used for rows
where consecutive values belong to different columns and thus are of
disparate data types with values in different ranges.

Furthermore, when queries only access a subset of the columns of one
table, only the columns actually accessed need to be read from disk,
thereby making better use of IO throughput and memory. Unreferenced
columns will not take space in the memory based cache of the database.
Further, the traffic between CPU cache and main memory is reduced when
data is more compact, leading to better CPU utilization.



The column-wise format is substantially more compact and offers
substantially greater sequential access performance, as well as
greater random access performance in situations where many rows are
accessed together in a join. For single-row random access a row-wise
format offers higher performance as long as the data is in memory. In
practice, for large tables, the higher compression achieved with
column-wise storage allows keeping a larger portion of the data in
memory, leading to less frequent IO and consequently higher
performance.

One should not use column-wise storage in cases where columns are
frequently updated, specially if they are updated a single row per
statement. This will have performance substantially worse than
row-wise storage. Bulk inserts and deletes are however efficient with
column-wise storage.



H2 Creating Column Store Tables and Indices 

Any index or primary key, i.e. table, can be declared as stored
column-wise by the following declarations: A single table can have
multiple indices of which some are stored column-wise and some are
not. As with row-wise stored tables, the table row itself is stored
following the primary key index entry on the index tree leaf
corresponding to the entry. This arrangement is sometimes called a
clustered index.



The below declares the table xx to be stored column-wise.

create table xx (id int, data varchar, primary key (id) column);


The below adds a column-wise stored index to the table.

create column index xxi on xx (data);




The COLUMN keyword can come after the column list of the primary key
declaration of a table or anywhere between the CREATE and INDEX
keywords of a create index statement. Note that the BITMAP keyword
cannot be used together with the COLUMN keyword: Column-wise indices
will use bitmap compression when appropriate without this being
specified. A column-wise index is likely to be more space-efficient
than a row-wise bitmap index with the same key parts.

The directives for column compression in create table (NO COMPRESS, COMPRESS PREFIX) have no effect on column-wise stored tables. Data is compressed in a manner chosen at run time based on the data itself.



H2 Column Store Transaction Support


All SQL operations work identically for column or row-wise tables and
indices. The locking behavior is also identical, with row level 
locking with all isolation levels supported. The behavior of the read
committed isolation is non-locking, showing the pre-image of updated
data in the event of reading pages with uncommitted inserts or
updates. 

Recovery is by roll forward and checkpoints will only store committed states of the database, even if started at when there are uncommitted transactions pending.


H2 Column Space Utilization 


The system table db.dba.sys_col_info holds information about space utilization of column-wise indices.
This table is updated only after the db.dba.sys_index_space_stats procedure view has been accessed. Thus one must first do a selection from db.dba.sys_index_space_stats.

The columns of sys_col_info have the following meaning.

COI_TABLE  The table in question

COI_INDEX The index in question.

COI_NTH - The ordinal position of the column in question in the key.

COI_TYPE This indicates the type of compression entry the rest of the row concerns. For each column in the key, there is a row with coi_type set to -1, representing the total of the remaining fields. 


          COI_COLUMN - The name of the column concerned


                                                                        COI_PAGES  - This is the number of database pages allocated for storing data of this column.

   COI_CES - The count of compression entries for the column. A compression entry is logically an array of consecutive values that share a common compression format. Different parts of the same column may have different compression. 

COI_VALUES -  This is the count of values that are stored with the compression format in question.


  COI_BYTES  -  The is the number of bytes actually occupied by the compression entries concerned. Pages may not always by full, thus this metric can  be used to measure the page fill ratio, i.e. 100 * coi_bytes / (coi_n_pages * 8192.0) 



To see which columns take the most space and to see how full the pages are as well as the overall effectiveness of compression, one can do

select coi_column, coi_pages * 8192 as total_bytes, coi_bytes / (coi_pages * 8192.0) as page_fill, coi_bytes, 1.0 * coi_bytes / coi_values as ce_bytes_per_value, 8192.0 * coi_pages / coi_values as bytes_per_value from sys_col_info where coi_type = -1 order by coi_pages desc;

Note that issuing a query like 

select top 20 * from sys_index_space_stats order by iss_pages desc; 

will update the sys_col_info table which is initially empty.
The sys_index_space_stats view shows the number of pages used for the sparse row-wise index tree top for column-wise indices.
The number of rows shown there for column-wise indices is the number of entries of the sparse index, not the row-count of the index. The space utilization here will be under 1% of the total for a column-wise index. 

Below we look at space utilization of the O column of the primary key of the RDF_QUAD table.


select * from sys_col_info where coi_index = 'DB.DBA.RDF_QUAD' and coi_column = 'O';
coi_table                                                                         coi_index                                                                         coi_nth           coi_type          coi_column                                                                        coi_pages            coi_ces              coi_values           coi_bytes
VARCHAR NOT NULL                                                                  VARCHAR NOT NULL                                                                  INTEGER NOT NULL  INTEGER NOT NULL  VARCHAR                                                                           INTEGER              INTEGER              INTEGER              INTEGER
_______________________________________________________________________________

DB.DBA.RDF_QUAD                                                                   DB.DBA.RDF_QUAD                                                                   2                 -1                O                                                                                 654663               0                    1252064815           4617808494
DB.DBA.RDF_QUAD                                                                   DB.DBA.RDF_QUAD                                                                   2                 1                 O                                                                                 0                    229074               97104862             947215
DB.DBA.RDF_QUAD                                                                   DB.DBA.RDF_QUAD                                                                   2                 3                 O                                                                                 0                    3227395              490806316            3905658370
DB.DBA.RDF_QUAD                                                                   DB.DBA.RDF_QUAD                                                                   2                 4                 O                                                                                 0                    94038                17227799             8554746
DB.DBA.RDF_QUAD                                                                   DB.DBA.RDF_QUAD                                                                   2                 6                 O                                                                                 0                    389126               551074747            579191659
DB.DBA.RDF_QUAD                                                                   DB.DBA.RDF_QUAD                                                                   2                 8                 O                                                                                 0                    160814               48480188             12026273
DB.DBA.RDF_QUAD                                                                   DB.DBA.RDF_QUAD                                                                   2                 10                O                                                                                 0                    652817               47370903             111430231


The top line is the overall summary across all the compression types. 
The below lines give the information per compression type. The values of  coi_type  mean the following: 

1 - run length. The value occurs once, followed by the number of repetitions  
- 3 array  - Values are consecutively stored without compression, the array elements are 4 or 8 byte depending on range, for variable length types some compression applies because values differing only in their last byte will only have the last byte stored.

- 4 bitmap  - For closely spaced unique ascending values, the bitmap has a start value in full and a bitmap with the nth bit set if start + nth occurs in the column. 

6 - dictionary -  For non-ordered, low cardinality columns there can be a dictionary with either 4 or 8 bytes per entry, depending on the number of distinct values being encoded. The compression entry is prefixed by an array with the values in full, followed by an array of positions in the dictionary.


8 - run length with small deltas - For repeating, closely spaced ascending values, the run length delta format stores a start value in full followed by an array of bytes of which 4 bits are a delta to the previous value and 4 bits are a run length. 


10 - integer delta with large deltas - This format stores an initial
value followed by stretches of non-ordered values within 64K of the
base value. There can be multiple such stretches, each prefixed with
a 32 bit delta from the base value. This is useful for closely spaced
medium cardinality values like dates or relatively sparse ascending
sequences, e.g. ascending sequences with a step of 1000 or more.



H1 Vectored Execution and Query Parallelization


Vectored execution means executing queries or stored procedures
simultaneously on multiple sets of parameters. Further, when a query
contains a join, a single invocation of the query will, with vectored
execution, execute every consecutive join step with multiple inputs.
When every stage of a query's evaluation is performed on a large
number of intermediate result rows at a time, two benefits are
obtained: The interpretation overhead disappears and 2. locality of
reference in joins can be better exploited.

For example, when joining as in 

select count (*) from part, lineitem where l_partkey = p_partkey and p_size < 23 option (loop, order);

the outermost loop of the query will look for parts with size < 23.
The part keys of these are used as lookup keys for an index on
l_partkey in lineitem. This index translates these values into values
of the primary key, l_orderkey, l_linenumber, which is then used to
get the data row with the price and discount. When each of these
steps is done with tens of thousands of values at the same time, the
SQL interpretation overhead is almost completely eliminated and
locality can be exploited when accessing nearby rows. The chance of
hitting nearby rows also increases when the size of the intermediate
result batch increases.




H2 Automatic Query Parallelization 

If a query does not modify data, executes in read-committed isolation
and contains some form of aggregation or order by, it can be
automatically parallelized. Parallelization typically splits the
quire's outermost loop into approximately equal size chunks which are
independently evaluated each on its own thread. The results are
merged together when all are ready and are combined in an aggregation
or order by. This is entirely transparent to the user.


H2 Configuration Parameters for Vectoring and Parallelization 


The following virtuoso.ini [Parameters] section entries concern query parallelization and vectoring.


AsyncQueueMaxThreads

This sets the number of threads in a pool that is used for getting extra threads for running queries and for   aq_request.  Each running statement has at least one thread that is not allocated from this pool plus zero or more threads from this pool. 
Setting the pool size to the number of cores plus a few is a reasonable default. On platforms with core multithreading one can count a core thread as a core for purposes of this parameter.

If one expects to run many slow aq_requests (see async_queue (), aq_request () et al), then the number of threads should be increased by the number of slow threads one expects.
Slow threads are typically IO bound threads used for web crawling or such long latency, low CPU activity.


ThreadsPerQuery 

This is the maximum number of threads that can be claimed from the thread pool by a single query. A value of one means that no query parallelization will take place and all queries will run single threaded. 
The number of cores on the machine is a reasonable default if running large queries.
Note that since every query is served by at least one thread, the fact of a single query taking all the extra threads will not prevent other queries from progressing.



VectorSize

This is the number of simultaneous sets of query variable  bindings processed at one time. The default is 10000, which is good for most cases.
If we are evaluating the query select count (*) from t1 a, t1 b where a.row_no + 1 = b.row_no option (loop, order), with vector size of 10000, then 10000 rows of t1 a will be fetched first, 1  will be added to the 10000 row_no   values and then the corresponding row of t1 b will be fetched for the 10000 row_no's of t1 a. This process will repeat until enough batches of t1 a have been fetched to come to its end. 


AdjustVectorSize

Using a larger vector size when evaluating large queries with indexed
random access can yield up to a 3x speed up relative to using the
default vector size. Always using a large vector size will however
prohibitively increase the overhead of running small queries. For
this reason there is a possibility of adaptively selecting the vector
size. Setting this to 1 will enable this feature. The SQL execution
engine will increase the vector size when it sees an index lookup that
does not get good locality, i.e. after sorting the keys to look for,
too few consecutive lookups fall on the same page. Having more keys
to look up increases the chance that consecutive keys should be found
on the same page, thus eliminating much of the index lookup cost.

MaxVectorSize 

When AdjustVectorSize is on, this setting gives the maximum vector size. The default is 1000000 and the largest allowed value is about 3500000. 








H1 Explicit Vectoring of Procedural Code


Vectored execution can be explicitly controlled for Virtuoso PL
code,either by declaring a whole procedure to be vectored or by
executing a block inside a procedure on multiple values at one time.






Vectored Procedures

A stored procedure may be declared vectored. This means that when
called from a statement operating on multiple values, a single call
of the procedure can take the whole batch of variable bindings the
statement is operating on in a single invocation. This saves
invocation and interpretation overhead and most importantly allows
running any SQL statements inside the procedure on multiple values at
once, creating possibilities for parallelization and exploitation of
locality. The vectored declaration consists of the VECTORED reserved
word at the start of the procedure body.


Consider the example of a lookup table:

create table person (p_id  int primary key, p_name varchar);

create table knows (p1 int references person, p2 int references person, primary key (p1, p2));

create procedure p_name (in code int)  returns varchar 
{ vectored; return (select p_name from person where p_id  = id); }

select  p_name (p1) from knows where p2 = 123;

This last statement is equivalent to 

select p_name from knows, person where p_id = p1 and p2 = 123;

For non-trivial transformations, hiding the logic inside a procedure
makes sense, Running the procedure vectored makes it so that
efficiency is not lost. For example, if person 123 knows 1000 people,
there will not be 1000 random lookups in person for the names but
rather a single vectored merge-style lookup accessing the rows in
order of id, thus saving time if the ids are nearby each other.
Furthermore, if the lookup is in read committed isolation the multiple
lookups can be scheduled on multiple threads.

The restrictions for vectored statement bodies apply to function bodies that are declared vectored. See the for vectored statement.


A vectored procedure can be called from a non-vectored procedure. In this case, the vectored procedure simply executes on a single set of values, as if it were not vectored. 
A vectored procedure can call a non-vectored procedure. When this happens, the non vectored procedure is called once for each set of eligible values, i.e. once for the first values of the arguments, once for the second values of the arguments and so forth.

A vectored procedure, if called from vectored code returns a return value for each set of arguments. 


A vectored procedure can have IN and OUT parameters. These have the
same semantics as in single value execution. When calling a
non-vectored procedure with an OUT or INOUT parameter, the argument in
the vectored caller must be declared to be of a boxed data type. See
the section vectoring and data types below.





FOR VECTORED Statement


FOR VECTORED ( <in-out> <variable> <data_type> [ := <value>], ... ) <compound_statement>


The for vectored statement allows executing a block of code on several
sets of variable bindings at once. The benefit of this is that any
database operations in such a block can be run on multiple sets of
parameters at once, allowing exploitation of locality and in some
cases running the operation on different bindings on a different
threads. Additionally, if vectored procedures are called from inside
such a block, the call is made with multiple bindings for the
parameters. The input variables of for vectored are initialized from
an array of scalar values. The statements inside the body are then
executed vectored, as if the operation were first made on all the
first values of the vectors, then on the second values and so forth.
Operations combining values from different places in the vectors are
not possible in the for vectored body but since vectored results can
be seen as arrays after the return of for vectored, any aggregation or
comparison between values in different positions of the same vector
can be done after the for vectored, simply accessing different
elements of the arrays produced.



The for vectored statement communicates with its environment through a
list of input and output variables. The input variables are marked
with the syntax IN <variable> <data_type> := <value>. The <value>
must be an expression evaluating to an array. The data type must
correspond to the element type of the array. When multiple input
variables are specified, the arrays initializing each must be of equal
length.

An output variable is marked with OUT <variable> := <>value>. The variable must be declared in a context outside of the for vectored statement. The value of the variable will be an array where each value of the vectored expression <value> is represented as a separate value.

Variables declared outside of a for vectored statement are visible in the body of for vectored and they appear as a  single value for all rows of the vectored section.

Consider the task of pair-wise adding the elements of two arrays:

create procedure a_add (in a1 int array, in a2 int array)
{
  declare res int array;
  res := make_array (length (a1, ' any' );
  for (i := 0; i < length (a1); i := i + 1)
    res[i] := a1[i] + a2[i];
  return res;
}

This can be expressed as 

create procedure a_add_v (in a1 int array, in a2 int array)
{
  declare res int array;
  for vectored (in n1 int := a1, in i2 int := a2, out res := r)
    {
       declare r int;
      r := i1 + i2;
    }
  return res;
}

The two procedures are identical in function. The second will make
use of vector instructions in the host CPU if available and will incur
less interpretation overhead, since the SQL run time will not need to
run a loop. In practice substantial benefit, up to an order of
magnitude, can be had from vectored execution with database operations
exhibiting significant locality. Bulk loads and bulk lookups are a
typical example.


H2 Limitations on Vectored Code



The body of for vectored or a vectored procedure may contain arbitrary
Virtuoso PL, except for loops and backward gotos. Conditional
expressions and statement are allowed, as well as any subqueries or
DML statements. Looping over a cursor is not allowed, since this is
a loop but scalar subqueries and selecting into variables in select
... into is allowed. Exception handlers are not allowed inside but
an exception handler outside of for vectored will catch errors
signaled from inside for vectored. for vectored statements may not
be nested and may not occur in the body of a vectored procedure. The
handler, being itself not in vectored code, will not be able to see
which specific value in a vectored section gave rise to the exception.


H2 Data Types and Vectoring

Parameters in vectored procedures or for vectored blocks can be
declared to be of the corresponding scalar data type. The vectoring
is thus in most cases transparent, the variable will simply have
multiple scalar values instead of one. The ANY type in a vectored
code section is represented as an array of serialized values. Thus
types that are represented as data structures in allocated memory,
e.g. arrays, hash tables, XML elements etc. will not work efficiently
with ANY vectored variables. In some cases, for example with streams
or dictionaries, assigning to a vectored ANY will lose the
information.


Therefore, if dealing with vectors of complex data types in vectored
code, the variable holding these must be declared as an ANY ARRAY.
With this type, the representation will be an array of pointers to
allocated memory, not an array of flat serialized values. The ANY
ARRAY type must be used instead of the customary ANY in all cases
involving complex values in vectored code. If dealing with vectors
of simple scalars like strings or numbers, the ANY type is generally
more efficient.
